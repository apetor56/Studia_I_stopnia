{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Today we are going to perform the simple classification of the amazon reviews' sentiment.\n",
    "\n",
    "### Please, download the dataset amazon_baby.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>review</th>\n      <th>rating</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Planetwise Flannel Wipes</td>\n      <td>These flannel wipes are OK, but in my opinion ...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Planetwise Wipe Pouch</td>\n      <td>it came early and was not disappointed. i love...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Annas Dream Full Quilt with 2 Shams</td>\n      <td>Very soft and comfortable and warmer than it l...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n      <td>This is a product well worth the purchase.  I ...</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Stop Pacifier Sucking without tears with Thumb...</td>\n      <td>All of my kids have cried non-stop when I trie...</td>\n      <td>5</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                                                name  \\\n0                           Planetwise Flannel Wipes   \n1                              Planetwise Wipe Pouch   \n2                Annas Dream Full Quilt with 2 Shams   \n3  Stop Pacifier Sucking without tears with Thumb...   \n4  Stop Pacifier Sucking without tears with Thumb...   \n\n                                              review  rating  \n0  These flannel wipes are OK, but in my opinion ...       3  \n1  it came early and was not disappointed. i love...       5  \n2  Very soft and comfortable and warmer than it l...       5  \n3  This is a product well worth the purchase.  I ...       5  \n4  All of my kids have cried non-stop when I trie...       5  "
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import string\r\n",
    "from sklearn.linear_model import LogisticRegression\r\n",
    "\r\n",
    "def remove_punctuation(text):\r\n",
    "    # if function reveice np.nan, return nothing\r\n",
    "    if not isinstance(text, str):\r\n",
    "        return ''\r\n",
    "    \r\n",
    "    import string\r\n",
    "    translator = str.maketrans('', '', string.punctuation)\r\n",
    "    return text.translate(translator)\r\n",
    "\r\n",
    "baby_df = pd.read_csv('amazon_baby.csv')\r\n",
    "baby_df.head()\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1 (data preparation)\n",
    "a) Remove punctuation from reviews using the given function.   \n",
    "b) Replace all missing (nan) revies with empty \"\" string.  \n",
    "c) Drop all the entries with rating = 3, as they have neutral sentiment.   \n",
    "d) Set all positive ($\\geq$4) ratings to 1 and negative($\\leq$2) to -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a)\r\n",
    "baby_df['review'] = baby_df['review'].apply(remove_punctuation)\r\n",
    "\r\n",
    "#short test: \r\n",
    "baby_df[\"review\"][4] == 'All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock'\r\n",
    "remove_punctuation(baby_df[\"review\"][4]) == 'All of my kids have cried nonstop when I tried to ween them off their pacifier until I found Thumbuddy To Loves Binky Fairy Puppet  It is an easy way to work with your kids to allow them to understand where their pacifier is going and help them part from itThis is a must buy book and a great gift for expecting parents  You will save them soo many headachesThanks for this book  You all rock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#b)\r\n",
    "baby_df['review'].replace(np.nan, '', inplace=True)\r\n",
    "\r\n",
    "#short test:\r\n",
    "baby_df[\"review\"][38] == baby_df[\"review\"][38]\r\n",
    "print(baby_df['review'][38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c)\r\n",
    "baby_df.drop(baby_df[baby_df['rating'] == 3].index, inplace=True)\r\n",
    "\r\n",
    "#short test:\r\n",
    "sum(baby_df[\"rating\"] == 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d) \r\n",
    "baby_df.loc[baby_df.rating <= 2, 'rating'] = -1\r\n",
    "baby_df.loc[baby_df.rating >= 4, 'rating'] =  1\r\n",
    "\r\n",
    "#short test:\r\n",
    "sum(baby_df[\"rating\"]**2 != 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "In order to analyze strings, we need to assign them numerical values. We will use one of the simplest string representation, which transforms strings into the $n$ dimensional vectors. The number of dimensions will be the size of our dictionary, and then the values of the vector will represent the number of appereances of the given word in the sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'we': 9, 'like': 6, 'apples': 2, 'hate': 5, 'oranges': 7, 'adore': 0, 'bananas': 3, 'and': 1, 'they': 8, 'dislike': 4}\n",
      "[[0 0 1 0 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 1 0 1 0 1]\n",
      " [1 0 0 1 0 0 0 0 0 0]\n",
      " [0 1 1 0 0 0 2 1 0 1]\n",
      " [0 0 0 1 1 0 0 0 1 0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\r\n",
    "\r\n",
    "vectorizer = CountVectorizer()\r\n",
    "reviews_train_example = [\"We like apples\",\r\n",
    "                   \"We hate oranges\",\r\n",
    "                   \"I adore bananas\",\r\n",
    "                   \"We like like apples and oranges\",\r\n",
    "                   \"They dislike bananas\"]\r\n",
    "\r\n",
    "X_train_example = vectorizer.fit_transform(reviews_train_example)\r\n",
    "print(vectorizer.vocabulary_)\r\n",
    "\r\n",
    "print(X_train_example.todense())\r\n",
    "\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'we': 9, 'like': 6, 'apples': 2, 'hate': 5, 'oranges': 7, 'adore': 0, 'bananas': 3, 'and': 1, 'they': 8, 'dislike': 4}\n",
      "[[0 0 0 1 0 0 1 0 1 0]\n",
      " [0 1 1 1 0 1 0 1 0 1]\n",
      " [0 0 0 1 0 0 0 0 0 1]]\n"
     ]
    }
   ],
   "source": [
    "reviews_test_example = [\"They like bananas\",\r\n",
    "                   \"We hate oranges bananas and apples\",\r\n",
    "                   \"We love bananas\"] #New word!\r\n",
    "\r\n",
    "X_test_example = vectorizer.transform(reviews_test_example)\r\n",
    "print(vectorizer.vocabulary_)\r\n",
    "\r\n",
    "print(X_test_example.todense())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should acknowledge few facts. Firstly, CountVectorizer does not take order into account. Secondly, it ignores one-letter words (this can be changed during initialization). Finally, for test values, CountVectorizer ignores words which are not in it's dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2 \n",
    "a) Split dataset into training and test sets.     \n",
    "b) Transform reviews into vectors using CountVectorizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a)\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "review_train, review_test, rating_train, rating_test = train_test_split(baby_df.review ,baby_df.rating, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spliting dataset into `rating` and `review` into `train & test` datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#b)\r\n",
    "vectorizer = CountVectorizer()\r\n",
    "vectorizer.fit(baby_df.review)\r\n",
    "\r\n",
    "review_train_T = vectorizer.transform(review_train)\r\n",
    "review_test_T = vectorizer.transform(review_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform `review` datasets into vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3 \n",
    "a) Train LogisticRegression model on training data (reviews processed with CountVectorizer, ratings as they were).   \n",
    "b) Print 10 most positive and 10 most negative words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lukasz\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>",
      "text/plain": "LogisticRegression()"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#a)\r\n",
    "model = LogisticRegression()\r\n",
    "model.fit(review_train_T, rating_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 positive words:  ['helped' 'perfect' 'highly' 'negative' 'plenty' 'lifesaver' 'satisfied'\n",
      " 'pleased' 'worry' 'excellent']\n",
      "Top 10 negative words:  ['worst' 'disappointing' 'poorly' 'worthless' 'concept' 'disappointment'\n",
      " 'horrible' 'useless' 'disappointed' 'theory']\n"
     ]
    }
   ],
   "source": [
    "#b)\r\n",
    "indices = np.argsort(model.coef_)\r\n",
    "words = np.array(vectorizer.get_feature_names_out())\r\n",
    "\r\n",
    "print('Top 10 positive words: ', words[indices[0, -10:]])\r\n",
    "print('Top 10 negative words: ', words[indices[0, :10]])\r\n",
    "#hint: model.coef_, vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorts indices by model coefficiets and prints first 10 positive and negative words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4 \n",
    "a) Predict the sentiment of test data reviews.   \n",
    "b) Predict the sentiment of test data reviews in terms of probability.   \n",
    "c) Find five most positive and most negative reviews.   \n",
    "d) Calculate the accuracy of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#a)\r\n",
    "pred = model.predict(review_test_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#b)\r\n",
    "prob = model.predict_proba(review_test_T)\r\n",
    "#hint: model.predict_proba()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103297    I was very excited when I heard Chicco was fin...\n",
      "135152    Weve been using Britax for our boy now 14 mont...\n",
      "123632    I did a TON of research before I purchased thi...\n",
      "161127    My dad just bought this car seat for memy son ...\n",
      "21557     Ok I read all the reviews already posted here ...\n",
      "Name: review, dtype: object\n",
      "16042     We have not had ANY luck with FisherPrice prod...\n",
      "10370     This product should be in the hall of fame sol...\n",
      "89902     I am so incredibly disappointed with the strol...\n",
      "120219    I have NEVER written a review before for anyth...\n",
      "175191    I had to return this stroller for three reason...\n",
      "Name: review, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#c)\r\n",
    "positive = np.argsort(prob[:,1])[-5:]\r\n",
    "print(review_test.iloc[positive])\r\n",
    "\r\n",
    "negative = np.argsort(prob[:,0])[-5:]\r\n",
    "print(review_test.iloc[negative])\r\n",
    "#hint: use the results of b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9295973134238853\n"
     ]
    }
   ],
   "source": [
    "#d) \r\n",
    "print(sum(pred == rating_test) / len(rating_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5\n",
    "In this exercise we will limit the dictionary of CountVectorizer to the set of significant words, defined below.\n",
    "\n",
    "\n",
    "a) Redo exercises 2-5 using limited dictionary.   \n",
    "b) Check the impact of all the words from the dictionary.   \n",
    "c) Compare accuracy of predictions and the time of evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "significant_words = ['love','great','easy','old','little','perfect','loves','well','able','car','broke','less','even','waste','disappointed','work','product','money','would','return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 positive words:  ['car' 'old' 'able' 'well' 'little' 'great' 'easy' 'love' 'perfect'\n",
      " 'loves']\n",
      "Top 10 negative words:  ['disappointed' 'return' 'waste' 'broke' 'money' 'work' 'even' 'would'\n",
      " 'product' 'less']\n",
      "103297    I was very excited when I heard Chicco was fin...\n",
      "134265    We bought this stroller after selling our belo...\n",
      "170607    PROS1 Good to grow with a toddler Its perfect ...\n",
      "25525     We bought this stroller about 2 weeks ago I ab...\n",
      "116072    Ive posted an UPDATE at the endFirst let me st...\n",
      "Name: review, dtype: object\n",
      "24325     This never worked right and I tried to return ...\n",
      "77915     This review is about Seller only Seller would ...\n",
      "35763     Day 1 Assembled it Had it up and running playi...\n",
      "168391    I loved all the features of the car seat  It i...\n",
      "2186      This is a long review but if you read the whol...\n",
      "Name: review, dtype: object\n",
      "Accuracy of prediction:  0.8669005427123625\n"
     ]
    }
   ],
   "source": [
    "#a)\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(baby_df.review,baby_df.rating, train_size=0.8)\r\n",
    "\r\n",
    "vectorizer = CountVectorizer()\r\n",
    "vectorizer.fit(significant_words)\r\n",
    "\r\n",
    "X_train_T_sig = vectorizer.transform(X_train.values)\r\n",
    "X_test_T_sig = vectorizer.transform(X_test.values)\r\n",
    "\r\n",
    "model_sig = LogisticRegression()\r\n",
    "model_sig.fit(X_train_T_sig, y_train)\r\n",
    "\r\n",
    "indices = np.argsort(model_sig.coef_)\r\n",
    "words = np.array(vectorizer.get_feature_names_out())\r\n",
    "print(\"Top 10 positive words: \", words[indices[0,-10:]])\r\n",
    "print(\"Top 10 negative words: \", words[indices[0,:10]])\r\n",
    "\r\n",
    "y_pred = model_sig.predict(X_test_T_sig)\r\n",
    "y_pred_proba = model_sig.predict_proba(X_test_T_sig)\r\n",
    "\r\n",
    "positive = np.argsort(y_pred_proba[:,1])[-5:]\r\n",
    "negative = np.argsort(y_pred_proba[:,0])[-5:]\r\n",
    "print(X_test.iloc[positive])\r\n",
    "print(X_test.iloc[negative])\r\n",
    "\r\n",
    "print('Accuracy of prediction: ', sum(y_pred == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "able: 0.0013279435149441358\n",
      "broke: 0.005287831260236116\n",
      "car: 0.012551652157347245\n",
      "disappointed: 0.001993154306148187\n",
      "easy: 7.092650322974392e-06\n",
      "even: 0.000604974931756302\n",
      "great: 0.045090823299666925\n",
      "less: 0.0898576535228941\n",
      "little: -0.0055539240616342125\n",
      "love: 0.017917659073607442\n",
      "loves: -0.0006839304637590155\n",
      "money: -0.026762579305358573\n",
      "old: 0.11101281206457021\n",
      "perfect: -0.0057083420758347134\n",
      "product: 0.0\n",
      "return: 7.662710542763792e-05\n",
      "waste: -0.009547348473792915\n",
      "well: 0.0011219703707157926\n",
      "work: 0.0\n",
      "would: 0.0\n"
     ]
    }
   ],
   "source": [
    "#b)\r\n",
    "coef_tuple = zip(vectorizer.get_feature_names_out(), model.coef_[0])\r\n",
    "for word, coef in coef_tuple:\r\n",
    "    print(f\"{word}: {coef}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#c)\r\n",
    "import sys, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792 µs ± 53.1 µs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n",
      "CPU times: total: 5.66 s\n",
      "Wall time: 6.51 s\n"
     ]
    }
   ],
   "source": [
    "%%time\r\n",
    "%%timeit\r\n",
    "model_sig.predict(X_test_T_sig)\r\n",
    "\r\n",
    "#hint: %time, %timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of prediction:  0.8669005427123625\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of prediction: ', sum(y_pred == y_test) / len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.2 ms ± 1.19 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "CPU times: total: 7.8 s\n",
      "Wall time: 9.15 s\n"
     ]
    }
   ],
   "source": [
    "%%time\r\n",
    "%%timeit\r\n",
    "model.predict(review_test_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of prediction:  0.9295973134238853\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of prediction: ', sum(pred == rating_test) / len(rating_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, accuracy of prediction is a little better in case we don't limit the dictionary to significant words, but prediction execution time is over 10 times faster with limited words, so sometimes it is worth to consider to limit our dictionary"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "fe1ceaac486e280189bf0ce10b1c361d86bf450b204a45f9caafbace2e46b60f"
    }
   },
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}